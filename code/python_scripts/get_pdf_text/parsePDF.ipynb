{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9853145-969b-4711-8fec-47f075e6fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split pdf file\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def extract_pages(source_pdf_path, output_pdf_path, start_page, end_page):\n",
    "    reader = PdfReader(source_pdf_path)\n",
    "    writer = PdfWriter()\n",
    "    \n",
    "    for i in range(start_page - 1, end_page):  # Adjust index since PyPDF2 is 0-indexed\n",
    "        writer.add_page(reader.pages[i])\n",
    "\n",
    "    with open(output_pdf_path, 'wb') as output_pdf:\n",
    "        writer.write(output_pdf)\n",
    "    print(f\"Pages from {start_page} to {end_page} have been extracted to {output_pdf_path}\")\n",
    "\n",
    "# Define the page ranges to extract\n",
    "page_ranges = [\n",
    "    (16, 19), (20, 26), (27, 37), (38, 43), (44, 49), (50, 71),\n",
    "    (72, 93), (94, 98), (99, 99), (100, 103), (104, 107), (108, 111),\n",
    "    (112, 123), (124, 128), (129, 136), (137, 141), (142, 148),\n",
    "    (149, 157), (158, 163), (164, 169), (170, 176), (177, 180),\n",
    "    (181, 185), (186, 202), (203, 639), (640, 656), (657, 663),\n",
    "    (664, 707), (708, 709)\n",
    "]\n",
    "\n",
    "source_pdf_path = 'CTCI.pdf'\n",
    "\n",
    "# Iterate over the page ranges and call the function for each range\n",
    "for start_page, end_page in page_ranges:\n",
    "    output_pdf_path = f'CTCI_{start_page}_{end_page}.pdf'\n",
    "    extract_pages(source_pdf_path, output_pdf_path, start_page, end_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c528e97-c155-4fdf-9237-702b88537810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VI \n",
      "BigO \n",
      "This is such an important concept that we are dedicating an entire (long!) chapter to it. \n",
      "Big 0 time is the language and metric we use to describe the efficiency of algorithms. Not understanding \n",
      "it thoroughly can really hurt you in developing an algorithm. Not only might you be judged harshly for \n",
      "not really understanding big 0, but you will also struggle to judge when your algorithm is getting faster or \n",
      "slower. \n",
      "Master this concept. \n",
      "~ An Analogy \n",
      "Imagine the following scenario: You've got a file on a hard drive and you need to send it to your friend who \n",
      "lives across the country. You need to get the file to your friend as fast as possible. How should you send it? \n",
      "Most people's first thought would be email, FTp, or some other means of electronic transfer. That thought is \n",
      "reasonable, but only half correct. \n",
      "If it's a small file, you're certainly right. It would take 5 -10 hours to get to an airport, hop on a flight, and \n",
      "then deliver it to your friend. \n",
      "But what if the file were really, really large? Is it possible that it's faster to physically deliver it via plane? \n",
      "Yes, actually it is. A one-terabyte (1 TB) file could take more than a day to transfer electronically. It would be \n",
      "much faster to just fly it across the country. If your file is that urgent (and cost isn't an issue), you might just \n",
      "want to do that. \n",
      "What if there were no flights, and instead you had to drive across the country? Even then, for a really huge \n",
      "file, it would be faster to drive. \n",
      "~ Time Complexity \n",
      "This is what the concept of asymptotic runtime, or big 0 time, means. We could describe the data transfer \n",
      "\"algorithm\" runtime as: \n",
      "• Electronic Transfer: 0 (5), where 5 is the size of the file. This means that the time to transfer the file \n",
      "increases linearly with the size of the file. (Yes, this is a bit of a simplification, but that's okay for these \n",
      "purposes.) \n",
      "Airplane Transfer: 0 (1) with respect to the size of the file. As the size of the file increases, it won't take \n",
      "any longer to get the file to your friend. The time is constant. \n",
      "38 Cracking the Coding interview, 6th Edition \n",
      "VII BigO \n",
      "No matter how big the constant is and how slow the linear increase is, linear will at some point surpass \n",
      "constant. \n",
      ".. ' 0(1) .. ' - --------::\",..:\"-- -\n",
      ".. ' \n",
      "......... ~(~) .... .. ' .. ' \n",
      "There are many more runtimes than this. Some ofthe most common ones are O( log N),O(N log N), \n",
      "O( N), O( N2) and O( 2N). There's no fixed list of possible runtimes, though. \n",
      "You can also have multiple variables in your runtime. For example, the time to paint a fence that's w meters \n",
      "wide and h meters high could be described as O( wh) .If you needed p layers of paint, then you could say \n",
      "that the time is 0 (whp). \n",
      "Big 0, Big Theta, and Big Omega \n",
      "If you've never covered big 0 in an academic setting, you can probably skip this subsection. It might \n",
      "confuse you more than it helps. This \"FYI\" is mostly here to clear up ambiguity in wording for people who \n",
      "have learned big 0 before, so that they don't say, \"But I thought big 0 meant..:' \n",
      "Academics use big 0, big 0 (theta), and big (1 (omega) to describe runtimes. \n",
      "• 0 (big 0): In academia, big 0 describes an upper bound on the time. An algorithm that prints all the \n",
      "values in an array could be described as O(N), but it could also be described as O( W), O(N3), or O( 2N) \n",
      "(or many other big 0 times). The algorithm is at least as fast as each of these; therefore they are upper \n",
      "bounds on the runtime. This is similar to a less-than-or-equal-to relationship. If Bob is X years old (I'll \n",
      "assume no one lives past age 130), then you could say X So 13e. It would also be correct to say that \n",
      "X So 1 J eee or X So 1 J eee J eee. It's technically true (although not terribly useful). Likewise, a simple \n",
      "algorithm to print the values in an array is 0 (N) as well as 0 (N3) or any runtime bigger than 0 (N). \n",
      "• Q (big omega): In academia, (1 is the equivalent concept but for lower bound. Printing the values in \n",
      "an array is 0 (N) as well as 0 (log N) and 0 ( 1). After all, you know that it won't be faster than those \n",
      "runtimes. \n",
      "• <:> (big theta): In academia, 0 means both 0 and (1. That is, an algorithm is 0 (N) if it is both 0 (N) and \n",
      "O(N).0 gives a tight bound on runtime. \n",
      "In industry (and therefore in interviews), people seem to have merged 0 and 0 together. Industry's meaning \n",
      "of big 0 is closer to what academics mean by 0, in that it would be seen as incorrect to describe printing an \n",
      "array as 0 (N2 ). I ndustry would just say this is 0 (N). \n",
      "For this book, we will use big 0 in the way that industry tends to use it: By always trying to offer the tightest \n",
      "description of the runtime. \n",
      "Best Case, Worst Case, and Expected Case \n",
      "We can actually describe our runtime for an algorithm in three different ways. \n",
      "CrackingTheCodinglnterview .com 16th Edition 39 \n",
      "VII BigO \n",
      "Let's look at this from the perspective of quick sort. Quick sort picks a random element as a \"pivot\" and then \n",
      "swaps values in the array such that the elements less than pivot appear before elements greater than pivot. \n",
      "This gives a \"partial sort:'Then it recursively sorts the left and right sides using a similar process. \n",
      "Best Case: If all elements are equal, then quick sort will, on average, just traverse through the array once. \n",
      "This is O( N). (This actually depends slightly on the implementation of quick sort. There are implementa ­\n",
      "tions, though, that will run very quickly on a sorted array.) \n",
      "• Worst Case: What if we get really unlucky and the pivot is repeatedly the biggest element in the array?, \n",
      "(Actually, this can easily happen. If the pivot is chosen to be the first element in the subarray and the \n",
      "array is sorted in reverse order, we'll have this situation.) In this case, our recursion doesn't divide the \n",
      "array in half and recurse on each half. It just shrinks the subarray by one element. This will degenerate \n",
      "toanO(W) runtime. \n",
      "Expected Case: Usually, though, these wonderful or terrible situations won't happen. Sure, sometimes \n",
      "the pivot will be very low or very high, but it won't happen over and over again. We can expect a runtime \n",
      "ofO(N log N). \n",
      "We rarely ever discuss best case time complexity, because it's not a very useful concept. After all, we could \n",
      "take essentially any algorithm, special case some input, and then get an O( 1) time in the best case. \n",
      "For many-probably most-algorithms, the worst case and the expected case are the same. Sometimes \n",
      "they're different, though, and we need to describe both of the runtimes. \n",
      "What is the relationship between best/worst/expected case and big a/theta/omega? \n",
      "It's easy for candidates to muddle these concepts (probably because both have some concepts of \"higher'; \n",
      "\"lower\" and \"exactly right\"), but there is no particular relationship between the concepts. \n",
      "Best, worst, and expected cases describe the big a (or big theta) time for particular inputs or scenarios. \n",
      "Big 0, big omega, and big theta describe the upper, lower, and tight bounds for the runtime. \n",
      "~ Space Complexity \n",
      "Time is not the only thing that matters in an algorithm . We might also care about the amount of memory­\n",
      "or space-required by an algorithm. \n",
      "Space complexity is a parallel concept to time complexity. If we need to create an array of size n, this will \n",
      "require 0 (n) space. If we need a two-dimensional array of size nxn, this will require 0 (n2) space. \n",
      "Stack space in recursive calls counts, too. For example, code like this would take 0 (n) time and O( n) space. \n",
      "1 int sum(int n) { /* Ex 1.*/ \n",
      "2 if (n <= a) { \n",
      "3 return B; \n",
      "4 } \n",
      "5 return n + sum(n-1); \n",
      "6 } \n",
      "Each call adds a level to the stack. \n",
      "1 sum(4) \n",
      "2 -> sum(3) \n",
      "3 -> sum(2) \n",
      "4 -> sum(l) \n",
      "5 -> sum(a) \n",
      "Each of these calls is added to the call stack and takes up actual memory. \n",
      "40 Cracking the Coding Interview, 6th Edition \n",
      "VII BigO \n",
      "However, just because you have n calls total doesn't mean it takes 0 (n) space. Consider the below func­\n",
      "tion, which adds adjacent elements between 0 and n: \n",
      "1 int pairSumSequence(int n) { /* Ex 2.*/ \n",
      "2 int sum = 0j \n",
      "3 for (int i = 0j i < nj i++) { \n",
      "4 sum += pairSum(i, i + l)j \n",
      "5 } \n",
      "6 return sum; \n",
      "7 } \n",
      "8 \n",
      "9 \n",
      "10 int pairSum(int a, int b) { \n",
      "return a + bj \n",
      "11 } \n",
      "There will be roughly O(n) calls to pairSum. However, those calls do not exist simultaneously on the call \n",
      "stack, so you only need 0 (1) space. \n",
      "~ Drop the Constants \n",
      "It is very possible for O(N) code to run faster than 0(1) code for specific inputs. Big 0 just describes the \n",
      "rate of increase. \n",
      "For this reason, we drop the constants in runtime. An algorithm that one might have described as 0 (2N) \n",
      "isactuallyO(N). \n",
      "Many people resist doing this. They will see code that has two (non-nested) for loops and continue this \n",
      "o (2N). They think they're being more \"precise:'They're not. \n",
      "Consider the below code: \n",
      "Min and Max 1 MinandMax2 \n",
      "1 int min = Integer.MAX_VALUEj 1 int min = Integer.MAX_VALUEj \n",
      "2 int max = Integer.MIN_VALUEj 2 int max = Integer.MIN_VALUEj \n",
      "3 for (int x : array) { 3 for (int x : array) { \n",
      "4 if (x < min) min = Xj 4 if (x < min) min = Xj \n",
      "5 if (x > max) max = Xj 5 } \n",
      "6 } 6 for (int x : array) { \n",
      "7 if (x > max) max = Xj \n",
      "8 } \n",
      "Which one is faster? The first one does one for loop and the other one does two for loops. But then, the first \n",
      "solution has two lines of code per for loop rather than one. \n",
      "If you're going to count the number of instructions, then you'd have to go to the assembly level and take \n",
      "into account that multiplication requires more instructions than addition, how the compiler would opti­\n",
      "mize something, and all sorts of other details. \n",
      "This would be horrendously complicated, so don't even start going down this road. Big 0 allows us to \n",
      "express how the runtime scales. We just need to accept that it doesn't mean that 0 (N) is always better than \n",
      "O( N2). \n",
      "(rackingThe(odinglnterview.com 16th Edition 41 \n",
      "VII SigO \n",
      "~ Drop the Non-Dominant Terms \n",
      "What do you do about an expression such as 0 (W + N)? That second N isn't exactly a constant. But it's \n",
      "not especially important. \n",
      "We already said that we drop constants . Therefore, 0 (N2 + N2) would be 0 (N2) .If we don't care about that \n",
      "latter N2 term, why would we care about N? We don't. \n",
      "You should drop the non-dominant terms. \n",
      "O(W + N) becomes O(W) . \n",
      "• O(N + log N) becomesO(N) . \n",
      "0(5*2N + 1000N100) becomesO(2 N). \n",
      "We might still havea sum in a runtime. Forexample, the expression 0(82 + A) cannot be reduced (without \n",
      "some special knowledge of A and B). \n",
      "The following graph depicts the rate of increase for some of the common big 0 times. \n",
      "OOog x) \n",
      "As you can see, 0 (X2) is much worse than 0 (x), but it's not nearly as bad as 0 (2X) or 0 (x! ). There are lots \n",
      "of runtimes worse than O( x! ) too, such as O( XX) or O( 2x * x!). \n",
      "~ Multi-Part Algorithms: Add vs. Multiply \n",
      "Suppose you have an algorithm that has two steps. When do you multiply the runtimes and when do you \n",
      "add them? \n",
      "This is a common source of confusion for candidates . \n",
      "42 Cracking the Coding Interview, 6th Edition \n",
      "Add the Runtimes: 0 (A + B) \n",
      "1 for (int a : arrA) { \n",
      "2 print(a); \n",
      "3 } \n",
      "4 \n",
      "5 for (int b : arrB) { \n",
      "6 print(b) ; \n",
      "7 } Multiply the Runtimes: O(A*B) \n",
      "1 for (int a : arrA) { \n",
      "2 for (int b : arrB) { \n",
      "3 print(a + \",\" + b); \n",
      "4 } \n",
      "5 } VII BigO \n",
      "In the example on the left, we do A chunks of work then B chunks of work. Therefore, the total amount of \n",
      "workisO(A + B). \n",
      "In the example on the right, we do B chunks of work for each element in A. Therefore, the total amount of \n",
      "workisO(A * B). \n",
      "In other words: \n",
      "If your algorithm is in the form \"do this, then, when you're all done, do that\" then you add the runtimes. \n",
      "If your algorithm is in the form \"do this for each time you do that\" then you multiply the runtimes. \n",
      "It's very easy to mess this up in an interview, so be careful. \n",
      "~ Amortized Time \n",
      "An ArrayLi st, or a dynamically resizing array, allows you to have the benefits of an array while offering \n",
      "flexibility in size. You won't run out of space in the ArrayList since its capacity will grow as you insert \n",
      "elements . \n",
      "An ArrayList is implemented with an array. When the array hits capacity, the ArrayList class will create a \n",
      "new array with double the capacity and copy all the elements over to the new array. \n",
      "How do you describe the runtime of insertion? This is a tricky question. \n",
      "The array could be full. If the array contains N elements , then inserting a new element will take 0 (N) time. \n",
      "You will have to create a new array of size 2N and then copy N elements over. This insertion will take 0 (N) \n",
      "time. \n",
      "However, we also know that this doesn't happen very often. The vast majority of the time insertion will be \n",
      "in 0(1) time. \n",
      "We need a concept that takes both into account. This is what amortized time does. It allows us to describe \n",
      "that, yes, this worst case happens every once in a while. But once it happens, it won't happen again for so \n",
      "long that the cost is \"amortized :' \n",
      "In this case, what is the amortized time? \n",
      "As we insert elements, we double the capacity when the size of the array is a power of 2.50 after X elements, \n",
      "we double the capacity at array sizes 1, 2, 4, 8, 16, ... , X. That doubling takes, respectively, 1, 2, 4, 8, 16, 32, \n",
      "64, ... , X copies. \n",
      "What is the sum of 1 + 2 + 4 + 8 + 16 + ... + X? If you read this sum left to right, it starts with 1 and doubles \n",
      "until it gets to X. If you read right to left, it starts with X and halves until it gets to 1. \n",
      "What then is the sum of X + X + X + Ys + ... + 1? This is roughly 2X. \n",
      "Therefore, X insertions take O( 2X) time. The amortized time for each insertion is O( 1). \n",
      "CrackingTheCodinglnterview.com 16th Edition 43 \n",
      "VII BigO \n",
      "~ Log N Runtimes \n",
      "We commonly see O( log N) in runtimes. Where does this come from? \n",
      "Let's look at binary search as an example. In binary search, we are looking for an example x in an N-element \n",
      "sorted array. We first compare x to the midpoint of the array. If x == middle, then we return. If x < \n",
      "middle, then we search on the left side of the array. If x > middle, then we search on the right side of \n",
      "the array. \n",
      "search 9 within {1, 5, 8, 9, 11, 13, 15, 19, 21} \n",
      "compare 9 to 11 -> smaller. \n",
      "search 9 within {1, 5, 8, 9, 11} \n",
      "compare 9 to 8 -> bigger \n",
      "search 9 within {9, 11} \n",
      "compare 9 to 9 \n",
      "return \n",
      "We start off with an N-element array to search. Then, after a single step, we're down to ~ elements. One \n",
      "more step, and we're down to X elements. We stop when we either find the value or we're down to just \n",
      "one element. \n",
      "The total runtime is then a matter of how many steps (dividing N by 2 each time) we can take until N \n",
      "becomes 1. \n",
      "N = 16 \n",
      "N = 8 /* divide by 2 */ \n",
      "N = 4 /* divide by 2 */ \n",
      "N = 2 /* divide by 2 */ \n",
      "N = 1 /* divide by 2 */ \n",
      "We could look at this in reverse (going from 1 to 16 instead of 16 to 1). How many times we can multiply 1 \n",
      "by 2 until we get N? \n",
      "N = 1 \n",
      "N = 2 \n",
      "N = 4 \n",
      "N = 8 \n",
      "N = 16 /* multiply by 2 */ \n",
      "/* multiply by 2 */ \n",
      "/* multiply by 2 */ \n",
      "/* multiply by 2 */ \n",
      "What is k in the expression 2k = N? This is exactly what log expresses. \n",
      "24 = 16 -> log,16 = 4 \n",
      "log,N = k -> 2k = N \n",
      "This is a good takeaway for you to have. When you see a problem where the number of elements in the \n",
      "problem space gets halved each time, that will likely be a O( log N) runtime. \n",
      "This is the same reason why finding an element in a balanced binary search tree is 0 (log N). With each \n",
      "comparison, we go either left or right. Half the nodes are on each side, so we cut the problem space in half \n",
      "each time. \n",
      "I What's the base of the log? That's an excellent question! The short answer is that it doesn't matter \n",
      "for the purposes of big O. The longer explanation can be found at \"Bases of Logs\" on page 630. \n",
      "~ Recursive Runtimes \n",
      "Here's a tricky one. What's the runtime of this code? \n",
      "1 int f(int n) { \n",
      "44 Cracking the Coding Interview, 6th Edition \n",
      "VII BigO \n",
      "2 if (n <= 1) { \n",
      "3 return 1; \n",
      "4 } \n",
      "5 return f(n -1) + f(n -1); \n",
      "6 } \n",
      "A lot of people will, for some reason, see the two calls to f and jump to 0 (N2). This is completely incorrect. \n",
      "Rather than making assumptions, let's derive the runtime by walking through the code. Suppose we call \n",
      "f (4). This calls f( 3) twice. Each of those calls to f (3) calls f( 2), until we get down to f (1). ---­f(3) \n",
      ",,/\" ~ \n",
      "/(2~ /f~ \n",
      "f(l) f(l) f(l) f(l) f(4) ----f(3) \n",
      ",,/\" ~ f(2) f(2} /~ ./ ~ f(l) f(l) f(l) f(l) \n",
      "How many calls are in this tree? (Don't count!) \n",
      "The tree will have depth N. Each node (Le., function call) has two children. Therefore , each level will have \n",
      "twice as many calls as the one above it. The number of nodes on each level is: \n",
      "Level # Nodes Also expressed as ... Or ... \n",
      "a 1 2° \n",
      "1 2 2 * previous level = 2 21 \n",
      "2 4 2 * previous level = 2 * 21 = 22 22 \n",
      "3 8 2 * previous level = 2 * 22 = 23 23 \n",
      "4 16 2 * previous level = 2 * 23 = 24 24 \n",
      "Therefore,therewillbe2 °+21 + 22 + 23 + 24 + ... + 2N(whichis2N+1 -1) nodes. (See \"Sum of \n",
      "Powers of 2\" on page 630.) \n",
      "Try to remember this pattern. When you have a recursive function that makes multiple calls, the runtime will \n",
      "often (but not always) look like O( branches dePth), where branches is the number of times each recursive \n",
      "call branches . In this case, this gives us 0 (2N). \n",
      "I As you may recall, the base of a log doesn't matter for big 0 since logs of different bases are \n",
      "only different by a constant factor. However, this does not apply to exponents . The base of an \n",
      "exponent does matter. Compare 2n and sn.lfyou expand sn, you get (23)n, which equals 23n, \n",
      "which equals 22n * 2n. As you can see, sn and 2n are different by a factor of 22n. That is very much \n",
      "not a constant factor! \n",
      "The space complexity of this algorithm will be 0 (N). Although we have 0 (2N) nodes in the tree total, only \n",
      "o (N) exist at any given time. Therefore, we would only need to have 0 (N) memory available. \n",
      "~ Examples and Exercises \n",
      "Big 0 time is a difficult concept at first. However, once it \"clicks;' it gets fairly easy. The same patterns come \n",
      "up again and again, and the rest you can derive. \n",
      "We'll start off easy and get progressively more difficult. \n",
      "(rackingThe(odinglnterview .com 16th Edition 4S \n",
      "VII BigO \n",
      "Example 1 \n",
      "What is the runtime of the below code? \n",
      "1 void foo(int[] array) { \n",
      "2 int sum = 6; \n",
      "3 int product = 1; \n",
      "4 for (int i = 6; i < array.length ; i++) { \n",
      "5 sum += array[i]; \n",
      "6 } \n",
      "7 for (int i = 6; i < array.length; i++) { \n",
      "8 product *= array[i] ; \n",
      "9 } \n",
      "16 System.out.println(sum + \". n + product); \n",
      "11 } \n",
      "This will take 0 (N) time. The fact that we iterate through the array twice doesn't matter. \n",
      "Example 2 \n",
      "What is the runtime of the below code? \n",
      "1 void printPairs(int[] array) { \n",
      "2 for (int i = 6; i < array. length; i++) { \n",
      "3 for (int j = 6; j < array. length; j++) { \n",
      "4 System.out.println (array[i] + \",n + array[j]); \n",
      "5 } \n",
      "6 } \n",
      "7 } \n",
      "The inner for loop has 0 (N) iterations and it is called N times. Therefore, the runtime is 0 (N2). \n",
      "Another way we can see this is by inspecting what the \"meaning\" of the code is. It is printing all pairs (two­\n",
      "element sequences). There are O( W) pairs; therefore, the runtime is O(W). \n",
      "Example 3 \n",
      "This is very similar code to the above example, but now the inner for loop starts at i + 1. \n",
      "1 void printunorderedPairs(int[] array) { \n",
      "2 for (int i = 6; i < array.length; i++) { \n",
      "3 for (int j = i + 1; j < array.length ; j++) { \n",
      "4 System.out .println(array[i] + \".n + array[j]); \n",
      "5 } \n",
      "6 } \n",
      "7 } \n",
      "We can derive the runtime several ways. \n",
      "I This pattern of for loop is very common. It's important that you know the runtime and that you \n",
      "deeply understand it. You can't rely on just memorizing common runtimes. Deep comprehen­\n",
      "sion is important. \n",
      "Counting the Iterations \n",
      "The first time through j runs for N -1 steps. The second time, it's N -2 steps. Then N -3 steps. And so on. \n",
      "Therefore , the number of steps total is: \n",
      "(N-l) + (N-2) + (N-3) + ... + 2 + 1 \n",
      "46 Cracking the Coding Interview, 6th Edition \n",
      "VII Big 0 \n",
      "= 1 + 2 + 3 + .•• + N-1 \n",
      "= sum of 1 through N-1 \n",
      "N(N-l) \n",
      "The sum of 1 through N -1 is -2-(see \"Sum of Integers 1 through N\" on page 630)' so the runtime will \n",
      "beO(W) . \n",
      "What It Means \n",
      "Alternatively , we can figure out the runtime by thinking about what the code \"means:' It iterates through \n",
      "each pair of values for (i, j) where j is bigger than i. \n",
      "There are W total pairs. Roughly half of those will have i < j and the remaining half will have i > j. This \n",
      "code goes through roughly Nh pairs so it does 0 (N2) work. \n",
      "Visualizing What It Does \n",
      "The code iterates through the following (i, j) pairs when N = 8: \n",
      "(0, 1) (0, 2) (0, 3) (0, 4) (0, 5) (0, 6) (0, 7) \n",
      "(1, 2) (1, 3) (1, 4) (1, 5) (1, 6) (1, 7) \n",
      "(2, 3) (2, 4) (2, 5) (2, 6) (2, 7) \n",
      "(3, 4) (3, 5) (3, 6) (3, 7) \n",
      "(4, 5) (4, 6) (4, 7) \n",
      "(5, 6) (5, 7) \n",
      "(6, 7) \n",
      "This looks like half of an NxN matrix, which has size (roughly) N%. Therefore, it takes O( N2) time. \n",
      "Average Work \n",
      "We know that the outer loop runs N times. How much work does the inner loop do? It varies across itera­\n",
      "tions, but we can think about the average iteration. \n",
      "What is the average value of 1, 2, 3, 4, 5, 6, 7, 8, 9, 1e? The average value will be in the \n",
      "middle, so it will be roughly S. (We could give a more precise answer, of course, but we don't need to for \n",
      "big 0.) \n",
      "What about for 1, 2, 3, •.• , N? The average value in this sequence is N/ 2. \n",
      "Therefore , since the inner loop does ~ work on average and it is run N times, the total work is N% which \n",
      "isO(W). \n",
      "Example 4 \n",
      "This is similar to the above, but now we have two different arrays. \n",
      "1 void printUnorderedPairs(int[] arrayA, int[] arrayB) { \n",
      "2 for (int i = 0; i < arrayA.length; i++) { \n",
      "3 for (int j = 0; j < arrayB.length; j++) { \n",
      "4 if (arrayA[i] < arrayB[j]) { \n",
      "5 System.out.println(arrayA[i] + \",\" + arrayB[j]); \n",
      "6 } \n",
      "7 } \n",
      "8 } \n",
      "9 } \n",
      "We can break up this analysis. The if-statement within j's for loop is 0 (1) time since it's just a sequence of \n",
      "constant-time statements . \n",
      "We now have this: \n",
      "1 void printUnorderedPairs(int[] arrayA, int[] arrayB) { \n",
      "CrackingTheCodinglnterv iew.com 16th Edition 47 \n",
      "VII BigO \n",
      "2 for (int i = e; i < arrayA.length; i++) { \n",
      "3 for (int j = e; j < arrayB.length; j++) { \n",
      "4 /* 0(1) work */ \n",
      "5 } \n",
      "6 } \n",
      "7 } \n",
      "For each element of arrayA, the inner for loop goes through b iterations, where b = arrayB . length. \n",
      "If a = arrayA.length,thentheruntimeisO(ab) . \n",
      "If you said O( N2), then remember your mistake for the future. It's not O( N2) because there are two different \n",
      "inputs. Both matter. This is an extremely common mistake. \n",
      "ExampleS \n",
      "What about this strange bit of code? \n",
      "1 void printUnorderedPairs(int[] arrayA, int[] arrayB) { \n",
      "2 for (int i = e; i < arrayA.length; i++) { \n",
      "3 for (int j = e; j < arrayB.length; j++) { \n",
      "4 for (int k = e; k < 1eeeee; k++) { \n",
      "5 System.out.println(arrayA[i] + \",. + arrayB[j]); \n",
      "6 } \n",
      "7 } \n",
      "8 } \n",
      "9 } \n",
      "Nothing has really changed here. 100,000 units of work is still constant, so the runtime is O( ab). \n",
      "Example 6 \n",
      "The following code reverses an array. What is its runtime? \n",
      "1 void reverse(int[] array) { \n",
      "2 for (int i = e; i < array.length / 2; i++) { \n",
      "3 int other = array.length -i -1; \n",
      "4 int temp = array[i]j \n",
      "5 array[i] = array[other]; \n",
      "6 array[other] = temp; \n",
      "7 } \n",
      "8 } \n",
      "This algorithm runs in O( N) time. The fact that it only goes through half of the array (in terms of iterations) \n",
      "does not impact the big 0 time. \n",
      "Example 7 \n",
      "Which of the following are equivalent to 0 (N)? Why? \n",
      "• 0 (N + P), where P < ~ \n",
      "O(2N) \n",
      "O(N + log N) \n",
      "• O(N + M) \n",
      "Let's go through these. \n",
      "If P < ~,then we know that N is the dominant term so we can drop the 0 (P). \n",
      "• O(2N) isO(N) since we drop constants. \n",
      "48 Cracking the Coding Interview, 6th Edition \n",
      "VII BigO \n",
      "O(N) dominatesO(log N),sowecandroptheO(log N). \n",
      "• There is no established relationship between Nand M, so we have to keep both variables in there. \n",
      "Therefore , all but the last one are equivalent to 0 (N). \n",
      "ExampleS \n",
      "Suppose we had an algorithm that took in an array of strings, sorted each string, and then sorted the full \n",
      "array. What would the runtime be? \n",
      "Many candidates will reason the following : sorting each string is 0 (N log N) and we have to do this for \n",
      "each string, so that's O(N*N log N). We also have to sort this array, so that's an additional O( N log N) \n",
      "work. Therefore, the total runtime is 0 (N2 log N + N log N), which is just 0 (N2 log N). \n",
      "This is completely incorrect. Did you catch the error? \n",
      "The problem is that we used N in two different ways. In one case, it's the length of the string (which string?). \n",
      "And in another case, it's the length of the array. \n",
      "In your interviews, you can prevent this error by either not using the variable \"N\" at all, or by only using it \n",
      "when there is no ambiguity as to what N could represent. \n",
      "In fact, I wouldn't even use a and b here, or m and n.lt's too easy to forget which is which and mix them up. \n",
      "An O( a2) runtime is completely different from an O( a*b) runtime. \n",
      "Let's define new terms-and use names that are logical. \n",
      "• Let 5 be the length of the longest string. \n",
      "• Let a be the length of the array. \n",
      "Now we can work through this in parts: \n",
      "• Sorting each string is 0 (5 log 5). \n",
      "• We have to do this for every string (and there are a strings), so that's 0 (a * 5 log 5). \n",
      "• Now we have to sort all the strings. There are a strings, so you'll may be inclined to say that this takes 0 (a \n",
      "log a) time. This is what most candidates would say. You should also take into account that you need \n",
      "to compare the strings. Each string comparison takes 0 (5) time. There are 0 (a log a) comparisons, \n",
      "therefore this will take 0 (a * 5 log a) time. \n",
      "If you add up these two parts, you getO(a*s(log a + log 5». \n",
      "This is it. There is no way to reduce it further. \n",
      "Example 9 \n",
      "The following simple code sums the values of all the nodes in a balanced binary search tree. What is its \n",
      "runtime? \n",
      "1 int sum(Node node) { \n",
      "2 if (node == nUll) { \n",
      "3 return a; \n",
      "4 } \n",
      "5 return sum(node .left) + node. value + sum(node.right); \n",
      "6 } \n",
      "Just because it's a binary search tree doesn't mean that there is a log in it! \n",
      "We can look at this two ways. \n",
      "CrackingTheCodinglnterview .com 16th Edition 49 \n",
      "VII BigO \n",
      "What It Means \n",
      "The most straightforward way is to think about what this means. This code touches each node in the tree \n",
      "once and does a constant time amount of work with each \"touch\" (excluding the recursive calls). \n",
      "Therefore, the runtime will be linear in terms of the number of nodes. If there are N nodes, then the runtime \n",
      "isO(N). \n",
      "Recursive Pattern \n",
      "On page 44, we discussed a pattern for the runtime of recursive functions that have multiple branches. \n",
      "Let's try that approach here. \n",
      "We said that the runtime of a recursive function with multiple branches is typically O(branchesdePth). \n",
      "There are two branches at each call, so we're looking at 0 (2dePth). \n",
      "At this point many people might assume that something went wrong since we have an exponential algo­\n",
      "rithm-that something in our logic is flawed or that we've inadvertently created an exponential time algo­\n",
      "rithm (yikes!). \n",
      "The second statement is correct. We do have an exponential time algorithm, but it's not as bad as one might \n",
      "think. Consider what variable it's exponential with respect to. \n",
      "What is depth? The tree is a balanced binary search tree. Therefore, if there are N total nodes, then depth \n",
      "is roughly log N. \n",
      "By the equation above, we get 0 (210g N). \n",
      "Recall what log2 means: \n",
      "2P = Q -> log2Q = P \n",
      "What is 210g N? There is a relationship between 2 and log, so we should be able to simplify this. \n",
      "Let P = 210g N. By the definition of log2' we can write this as logl = log2N. This means that P N. \n",
      "Let P = 210g N \n",
      "-> logl = log2N \n",
      "-> P = N \n",
      "_ > 210g N = N \n",
      "Therefore , the runtime of this code is O( N), where N is the number of nodes. \n",
      "Example 10 \n",
      "The following method checks if a number is prime by checking for divisibility on numbers less than it. It only \n",
      "needs to go up to the square root of n because if n is divisible by a number greater than its square root then \n",
      "it's divisible by something smaller than it. \n",
      "For example, while 33 is divisible by 11 (which is greater than the square root of 33), the \"counterpart\" to 11 \n",
      "is 3 (3 * 11 = 33). 33 will have already been eliminated as a prime number by 3. \n",
      "What is the time complexity of this function? \n",
      "1 boolean isPrime(int n) { \n",
      "2 for (int x = 2; x * x (= n; x++) { \n",
      "3 if (n % x == El) { \n",
      "4 return false; \n",
      "5 } \n",
      "6 } \n",
      "7 return true; \n",
      "so Cracking the Coding Interview, 6th Edition \n",
      "VII BigO \n",
      "8 } \n",
      "Many people get this question wrong. If you're careful about your logic, it's fairly easy. \n",
      "The work inside the for loop is constant. Therefore, we just need to know how many iterations the for loop \n",
      "goes through in the worst case. \n",
      "The for loop will start when x = 2 and end when x*x = n. Or, in other words, it stops when x = vn (when \n",
      "x equals the square root of n). \n",
      "This for loop is really something like this: \n",
      "1 boolean isPrime(int n) { \n",
      "2 for (int x = 2j x <= sqrt(n)j x++) { \n",
      "3 if (n % x == e) { \n",
      "4 return falsej \n",
      "5 } \n",
      "6 } \n",
      "7 return truej \n",
      "8 } \n",
      "This runs in 0 (vn) time. \n",
      "Example 11 \n",
      "The following code computes n! (n factorial). What is its time complexity? \n",
      "1 int factorial(int n) { \n",
      "2 if(n<e){ \n",
      "3 return -1j \n",
      "4 } else if (n == e) { \n",
      "5 return 1j \n",
      "6 } else { \n",
      "7 return n * factorial(n -l)j \n",
      "8 } \n",
      "9 } \n",
      "This is just a straight recursion from n to n -1 to n -2 down to 1. It will take 0 (n) time. \n",
      "Example 12 \n",
      "This code counts all permutations of a string. \n",
      "1 void permutation(String str) { \n",
      "2 permutation(str, UJJ)j \n",
      "3 } \n",
      "4 \n",
      "5 void permutation(String str, String prefix) { \n",
      "6 if (str.length() == e) { \n",
      "7 System.out.println(prefix)j \n",
      "8 } else { \n",
      "9 for (int i = ej i < str.length()j i++) { \n",
      "Ie String rem = str.substring(e, i) + str.substring (i + 1)j \n",
      "11 permutation(rem, prefix + str.charAt( i»j \n",
      "12 } \n",
      "13 } \n",
      "14 } \n",
      "This is a (very!) tricky one. We can think about this by looking at how many times permutation gets called \n",
      "and how long each call takes. We'll aim for getting as tight of an upper bound as possible. \n",
      "CrackingThe Codinglnterview.com 16th Edition S1 \n",
      "VII SigO \n",
      "How many times does permutation get called in its base case? \n",
      "If we were to generate a permutation, then we would need to pick characters for each \"slot:' Suppose we \n",
      "had 7 characters in the string. In the first slot, we have 7 choices. Once we pick the letter there, we have 6 \n",
      "choices for the next slot. (Note that this is 6 choices for each of the 7 choices earlier.) Then 5 choices for the \n",
      "next slot, and so on. \n",
      "Therefore, the total number of options is 7 * 6 * 5 * 4 * 3 * 2 * 1, which is also expressed as 7! (7 factorial). \n",
      "This tells us that there are n! permutations . Therefore, permutation is called n! times in its base case \n",
      "(when prefix is the full permutation) . \n",
      "How many times does permutation get called before its base case? \n",
      "But, of course, we also need to consider how many times lines 9 through 12 are hit. Picture a large call tree \n",
      "representing all the calls. There are n! leaves, as shown above. Each leaf is attached to a path of length n. \n",
      "Therefore, we know there will be no more than n * n! nodes (function calls) in this tree. \n",
      "How long does each function call take? \n",
      "Executing line 7 takes O( n) time since each character needs to be printed. \n",
      "Line 10 and line 11 will also take 0 (n) time combined , due to the string concatenation . Observe that the \n",
      "sum of the lengths of rem, prefix, and str. charAt( i) will always be n. \n",
      "Each node in our call tree therefore corresponds to 0 (n) work. \n",
      "What is the total runtime? \n",
      "Since we are calling permutat ion 0 (n * n!) times (as an upper bound), and each one takes 0 (n) time, \n",
      "the total runtime will not exceed O( n2 * n!). \n",
      "Through more complex mathematics , we can derive a tighter runtime equation (though not necessarily a \n",
      "nice closed-form expression) . This would almost certainly be beyond the scope of any normal interview . \n",
      "Example 13 \n",
      "The following code computes the Nth Fibonacci number. \n",
      "1 int fib(int n) { \n",
      "2 if (n (= e) return e; \n",
      "3 else if (n == 1) return 1; \n",
      "4 return fib(n -1) + fib(n -2); \n",
      "5 } \n",
      "We can use the earlier pattern we'd established for recursive calls: O( branches dePth). \n",
      "There are 2 branches per call, and we go as deep as N, therefore the runtime is 0 (2N). \n",
      "I \n",
      "52 Through some very complicated math, we can actually get a tighter runtime. The time is indeed \n",
      "exponential, but it's actually closer to 0 ( 1. 6N). The reason that it's not exactly 0 (2N) is that, at \n",
      "the bottom of the call stack, there is sometimes only one call. It turns out that a lot of the nodes \n",
      "are at the bottom (as is true in most trees), so this single versus double call actually makes a big \n",
      "difference. Saying 0 (2N) would suffice for the scope of an interview, though (and is still techni­\n",
      "cally correct, if you read the note about big theta on page 39). You might get \"bonus points\" if \n",
      "you can recognize that it'll actually be less than that. \n",
      "Cracking the Coding Interview, 6th Edition \n",
      "VII BigO \n",
      "Generally speaking, when you see an algorithm with multiple recursive calls, you're looking at exponential \n",
      "runtime. \n",
      "Example 14 \n",
      "The following code prints all Fibonacci numbers from 0 to n. What is its time complexity? \n",
      "1 void allFib(int n) { \n",
      "2 for (int i = 8; i < n; i++) { \n",
      "3 System.out.println(i + \": » + fib(i)); \n",
      "4 } \n",
      "5 } \n",
      "6 \n",
      "7 int fib(int n) { \n",
      "8 if (n <= e) return e; \n",
      "9 else if (n == 1) return 1; \n",
      "1e return fib(n -1) + fib(n -2); \n",
      "11 } \n",
      "Many people will rush to concluding that since fib (n) takes 0 (2n) time and it's called n times, then it's \n",
      "O(n2n). \n",
      "Not so fast. Can you find the error in the logic? \n",
      "The error is that the n is changing. Yes, fib (n) takes O( 2n) time, but it matters what that value of n is. \n",
      "Instead, let's walk through each call. \n",
      "fib(l) -) 2' steps \n",
      "fib(2) -) 2' steps \n",
      "fib(3) -) 2' steps \n",
      "fib(4) -) 24 steps \n",
      "fib(n) -) 2\" steps \n",
      "Therefore, the total amount of work is: \n",
      "2' + 22 + 23 + 24 + ... + 2n \n",
      "As we showed on page 44, this is 20+1. Therefore, the runtime to compute the first n Fibonacci numbers \n",
      "(using this terrible algorithm) is still O( 2n). \n",
      "Example 1S \n",
      "The following code prints all Fibonacci numbers from 0 to n. However, this time, it stores (Le., caches) previ­\n",
      "ously computed values in an integer array. If it has already been computed, it just returns the cache. What \n",
      "is its runtime? \n",
      "1 void allFib(int n) { \n",
      "2 int[] memo = new int[n + 1]; \n",
      "3 for (int i = e; i < n; i++) { \n",
      "4 System.out.println(i + \": » + fib(i, memo)); \n",
      "5 } \n",
      "6 } \n",
      "7 \n",
      "8 int fib(int n, int[] memo) { \n",
      "9 if (n <= 8) return e; \n",
      "18 else if (n == 1) return 1; \n",
      "11 else if (memo[n] ) e) return memo[n]; \n",
      "12 \n",
      "13 memo[n] = fib(n -1, memo) + fib(n -2, memo); \n",
      "CrackingTheCodinglnterview.com 16th Edition 53 \n",
      "VII BigO \n",
      "14 return memo[n]; \n",
      "15 } \n",
      "Let's walk through what this algorithm does. \n",
      "fib(l) -> return 1 \n",
      "fib(2) \n",
      "fib(l) -) return 1 \n",
      "fib(0) -) return 0 \n",
      "store 1 at memo[2] \n",
      "fib(3) \n",
      "fib(2) -> lookup memo[2] -) return 1 \n",
      "fib(l) -) return 1 \n",
      "store 2 at memo[3] \n",
      "fib(4) \n",
      "fib(3) -) lookup memo[3] -) return 2 \n",
      "fib(2) -> lookup memo[2] -) return 1 \n",
      "store 3 at memo[4] \n",
      "fib(5) \n",
      "fib(4) -) lookup memo[4] -) return 3 \n",
      "fib(3) -) lookup memo[3] -) return 2 \n",
      "store 5 at memo[5] \n",
      "At each call to fib (i), we have already computed and stored the values for fib( i -1) and fib (i -2). \n",
      "We just look up those values, sum them, store the new result, and return. This takes a constant amount of \n",
      "time. \n",
      "We're doing a constant amount of work N times, so this is 0 (n) time. \n",
      "This technique, called memoization, is a very common one to optimize exponential time recursive algo­\n",
      "rithms. \n",
      "Example 16 \n",
      "The following function prints the powers of 2 from 1 through n (inclusive ). For example, if n is 4, it would \n",
      "print 1,2, and 4. What is its runtime? \n",
      "1 int powersOf2(int n) { \n",
      "2 if (n < 1) { \n",
      "3 return 0; \n",
      "4 } else if (n == 1) { \n",
      "5 System.out.println(l); \n",
      "6 return 1; \n",
      "7 } else { \n",
      "8 int prev = powersOf2(n / 2); \n",
      "9 int curr = prev * 2; \n",
      "10 System.out.println(curr); \n",
      "11 return curr; \n",
      "12 } \n",
      "13 } \n",
      "There are several ways we could compute this runtime. \n",
      "What It Does \n",
      "Let's walk through a call like powersOf2 (50). \n",
      "powersOf2(50) \n",
      "-) powersOf2(25) \n",
      "S4 Cracking the Coding Interview, 6th Edition \n",
      "-> powersOf2(12) \n",
      "-> powersOf2(6) \n",
      "-> powersOf2(3) \n",
      "-> powersOf2(1) \n",
      "-> print & return 1 \n",
      "print & return 2 \n",
      "print & return 4 \n",
      "print & return 8 \n",
      "print & return 16 \n",
      "print & return 32 VII BigO \n",
      "The runtime, then, is the number of times we can divide 50 (or n) by 2 until we get down to the base case (1). \n",
      "As we discussed on page 44, the number of times we can halve n until we get 1 is 0 (log n). \n",
      "What It Means \n",
      "We can also approach the runtime by thinking about what the code is supposed to be doing. It's supposed \n",
      "to be computing the powers of 2 from 1 through n. \n",
      "Each call to powersOf2 results in exactly one number being printed and returned (excluding what happens \n",
      "in the recursive calls). So if the algorithm prints 13 values at the end, then powersOf2 was called 13 times. \n",
      "In this case, we are told that it prints all the powers of 2 between 1 and n. Therefore, the number of times \n",
      "the function is called (which will be its runtime) must equal the number of powers of 2 between 1 and n. \n",
      "There are log N powers of 2 between 1 and n. Therefore, the runtime is 0 (log n). \n",
      "Rate of Increase \n",
      "A final way to approach the runtime is to think about how the runtime changes as n gets bigger. After all, \n",
      "this is exactly what big 0 time means. \n",
      "If N goes from P to P+1, the number of calls to powersOfTwo might not change at all. When will the \n",
      "number of calls to powersOfTwo increase? It will increase by 1 each time n doubles in size. \n",
      "So, each time n doubles, the number of calls to powersOfTwo increases by 1. Therefore, the number of \n",
      "calls to powersOfTwo is the number of times you can double 1 until you get n. It is x in the equation 2x \n",
      "= n. \n",
      "What is x? The value of x is log n. This is exactly what meant by x = log n. \n",
      "Therefore, the runtime is 0 (log n). \n",
      "Additional Problems \n",
      "VI.l The following code computes the product of a and b. What is its runtime? \n",
      "int product(int a, int b) { \n",
      "int sum = aj \n",
      "for (int i = aj i < bj i++) { \n",
      "sum += aj \n",
      "} \n",
      "return sumj \n",
      "} \n",
      "VI.2 The following code computes abo What is its runtime? \n",
      "int power(int a, int b) { \n",
      "if (b < a) { \n",
      "CrackingTheCodinglnterview.com 16th Edition SS \n",
      "VII Big 0 \n",
      "} return a; II error \n",
      "} else if (b == a) { \n",
      "return 1; \n",
      "} else { \n",
      "return a * power(a, b -1); \n",
      "} \n",
      "VI.3 The following code computes a % b. What is its runtime? \n",
      "int mod(int a, int b) { \n",
      "} if (b <= a) { \n",
      "return -1; \n",
      "} \n",
      "int div = a I b; \n",
      "return a -div * b; \n",
      "VI.4 The following code performs integer division. What is its runtime (assume a and b are both \n",
      "positive)? \n",
      "int div(int a, int b) { \n",
      "int count = a; \n",
      "} int sum = b; \n",
      "while (sum <= a) { \n",
      "sum += b; \n",
      "count++; \n",
      "} \n",
      "return count; \n",
      "VI.5 The following code computes the [integer) square root of a number. If the number is not a \n",
      "perfect square (there is no integer square root), then it returns -1 .It does this by successive \n",
      "guessing. If n is 100, it first guesses SO. Too high? Try something lower -halfway between 1 \n",
      "and SO. What is its runtime? \n",
      "int sqrt(int n) { \n",
      "return sqrt_helper(n, 1, n); \n",
      "} \n",
      "int sqrt_helper(int n, int min, int max) { \n",
      "if (max < min) return -1; II no square root \n",
      "int guess = (min + max) I 2; \n",
      "if (guess * guess == n) { II found it! \n",
      "return guess; \n",
      "} else if (guess * guess < n) { II too low \n",
      "return sqrt_helper(n, guess + 1, max) ; II try higher \n",
      "} else { II too high \n",
      "return sqrt_helper(n, min, guess -1); II try lower \n",
      "} \n",
      "} \n",
      "VI.6 The following code computes the [integer) square root of a number. If the number is not \n",
      "a perfect square (there is no integer square root), then it returns -1. It does this by trying \n",
      "increasingly large numbers until it finds the right value (or is too high). What is its runtime? \n",
      "int sqrt(int n) { \n",
      "for (int guess = 1; guess * guess <= n; guess++) { \n",
      "if (guess * guess == n) { \n",
      "return guess; \n",
      "S6 Cracking the Coding Interview, 6th Edition \n",
      "VII BigO \n",
      "} \n",
      "} \n",
      "return -1; \n",
      "} \n",
      "VI.7 If a binary search tree is not balanced, how long might it take (worst case) to find an element \n",
      "in it? \n",
      "VI.S You are looking for a specific value in a binary tree, but the tree is not a binary search tree. \n",
      "What is the time complexity of this? \n",
      "VI.9 The appendToNew method appends a value to an array by creating a new, longer array and \n",
      "returning this longer array. You've used the appendToNew method to create a copyArray \n",
      "function that repeatedly calls appendToNew. How long does copying an array take? \n",
      "int[] copyArray(int[] array) { \n",
      "int[] copy = new int[e]; \n",
      "for (int value : array) { \n",
      "copy = appendToNew(copy, value); \n",
      "} \n",
      "return copy; \n",
      "} \n",
      "int[] appendToNew(int[] array, int value) { \n",
      "II copy all elements over to new array \n",
      "int[] bigger = new int[array.length + 1]; \n",
      "for (int i = e; i < array. length; i++) { \n",
      "} bigger[i] = array[i]; \n",
      "} \n",
      "II add new element \n",
      "bigger[bigger.length -1] = value; \n",
      "return bigger; \n",
      "VI.l0 The following code sums the digits in a number. What is its big 0 time? \n",
      "int sumDigits(int n) { \n",
      "int sum = e; \n",
      "while (n > e) { \n",
      "sum += n % 1e; \n",
      "n 1= 1e; \n",
      "} \n",
      "return sum; \n",
      "} \n",
      "VI.ll The following code prints all strings of length k where the characters are in sorted order. It \n",
      "does this by generating all strings of length k and then checking if each is sorted. What is its \n",
      "runtime? \n",
      "int numChars = 26; \n",
      "void printSortedStrings(int remaining) { \n",
      "printSortedStrings(remaining, U\"); \n",
      "} \n",
      "void printSortedStrings(int remaining, String prefix) { \n",
      "if (remaining == e) { \n",
      "if (islnOrder(prefix» { \n",
      "system.out.println(prefix); \n",
      "} \n",
      "CrackingTheCodinginterview .com 16th Edition 57 \n",
      "VII Big 0 \n",
      "} } else { \n",
      "for (int i = e; i < numChars ; i++) { \n",
      "} \n",
      "} char c = ithLetter(i); \n",
      "printSortedStrings(remaining -1, prefix + c); \n",
      "boolean islnOrder(String s) { \n",
      "for (int i = 1; i < s.length(); i++) { \n",
      "int prev ithLetter(s.charAt(i -1)); \n",
      "int curr = ithLetter(s.charAt(i)); \n",
      "if (prev > curr) { \n",
      "return false; \n",
      "} \n",
      "} \n",
      "return true; \n",
      "} \n",
      "char ithLetter(int i) { \n",
      "return (char) «(int) Ca') + i); \n",
      "} \n",
      "VI.12 The following code computes the intersection (the number of elements in common) of two \n",
      "arrays. It assumes that neither array has duplicates. It computes the intersection by sorting \n",
      "one array (array b) and then iterating through array a checking (via binary search) if each \n",
      "value is in b. What is its runtime? \n",
      "int intersection(int[] a, int[] b) { \n",
      "mergesort(b); \n",
      "int intersect = e; \n",
      "for (int x : a) { \n",
      "if (binarySearch(b, x) >= e) { \n",
      "intersect++ ; \n",
      "} \n",
      "} \n",
      "return intersect; \n",
      "} \n",
      "Solutions \n",
      "1. 0 (b). The for loop just iterates through b. \n",
      "2. 0 (b). The recursive code iterates through b calls, since it subtracts one at each level. \n",
      "3. 0 (1) .It does a constant amount of work. \n",
      "4. O( ~). The variable count will eventually equal ~. The while loop iterates count times. Therefore, it \n",
      "iterates ~ times. \n",
      "5. 0 (log n). This algorithm is essentially doing a binary search to find the square root. Therefore, the \n",
      "runtimeisO(log n). \n",
      "6. O(sqrt(n» . This is just a straightfo rward loop that stops when guess*guess > n (or, in other \n",
      "words, when guess > sqrt (n »). \n",
      "58 Cracking the Coding Interview, 6th Edition \n",
      "VII BigO \n",
      "7. 0 (n), where n is the number of nodes in the tree. The max time to find an element is the depth tree. The \n",
      "tree could be a straight list downwards and have depth n. \n",
      "8. 0 (n). Without any ordering property on the nodes, we might have to search through all the nodes. \n",
      "9. O( n2), where n is the number of elements in the array. The first call to appendToNew takes 1 copy. The \n",
      "second call takes 2 copies. The third call takes 3 copies. And so on. The total time will be the sum of 1 \n",
      "through n, which is O( n2). \n",
      "lO.O( log n). The runtime will be the number of digits in the number. A number with d digits can have a \n",
      "value up to led. If n = led, then d = log n. Therefore, the runtime is O( log n). \n",
      "11.0 (kck), where k is the length of the string and c is the number of characters in the alphabet. It takes \n",
      "O( ck) time to generate each string. Then, we need to check that each of these is sorted, which takes \n",
      "O(k) time. \n",
      "l2.0(b log b + a log b).First,wehavetosortarrayb,whichtakesO(b log b) time. Then, for each \n",
      "element in a, we do binary search in 0 (log b) time. The second part takes 0 (a log b) time. \n",
      "CrackingTheCodinglnterview .com 16th Edition S9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract text from pdf file and print as output\n",
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Iterate through each page and extract text\n",
    "        text = ''\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() + '\\n'  # Extract text from each page\n",
    "        \n",
    "    return text\n",
    "\n",
    "# Specify the path to your PDF\n",
    "pdf_path = 'CTCI_50_71.pdf'\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
